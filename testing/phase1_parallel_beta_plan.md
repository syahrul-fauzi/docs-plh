# Phase 1: Parallel Beta Testing Process Plan

## Overview
This document outlines the implementation of Phase 1, which establishes a parallel beta testing process combining the **Lawyers Hub** core development environment with **AI Gateway** capabilities.

## Goals
1.  **Infrastructure**: Enable simultaneous execution and verification of Core API and AI Gateway.
2.  **Integration**: Verify functional connectivity between the two systems.
3.  **Metrics**: Establish performance and completeness benchmarks.
4.  **Consistency**: Ensure data consistency across boundaries.

## Architecture

| Component | Port | Role | Testing Focus |
| :--- | :--- | :--- | :--- |
| **Lawyers Hub API** | `3003` | Core Business Logic, Tenants, Auth | Auth flow, Tenant resolution, Data persistence |
| **AI Gateway** | `3010` | LLM Orchestration, PII Masking | Prompt handling, Compliance, Response latency |

## Implementation Steps

### 1. Infrastructure Setup
- **Tooling**: Custom Node.js scripts in `scripts/phase1-beta/`.
- **Parallel Execution**: Leverage existing `turbo` setup + active dev terminals.
- **Monitoring**: simple health checks and latency logging.

### 2. Integration Testing
- **Scenario A: Auth Propagation**: Verify that a user authenticated in Core can access AI Gateway (if applicable) or that AI Gateway can validate tokens.
- **Scenario B: Tenant Context**: Verify that AI requests respect Tenant RLS.

### 3. Success Metrics (KPIs)
- **Availability**: Both services must be reachable (HTTP 200/4xx).
- **Latency**:
    - Core API Health: < 200ms
    - AI Gateway Health: < 200ms
- **Functionality**:
    - Core: Subdomain validation passes.
    - AI: Basic prompt echo/processing passes (simulated if no LLM key).

## Logging & Tracking
- Unified log format (JSON) for test executions.
- Error tracking via standard output capture.

## Deliverables
- `scripts/phase1-beta/` suite.
- Comparative Analysis Report (generated by script).
